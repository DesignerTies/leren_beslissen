{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eAbKZC3Q7tCR",
        "outputId": "304da858-c403-47d2-e67a-8ee19ddd92b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sales Data Sample:\n",
            "              Datum Betaaltype          Product  Aantal\n",
            "0  26-09-2022 00:53  Omzet pin  Buitenlands mix       1\n",
            "1  26-09-2022 00:52  Omzet pin        Heineken        1\n",
            "2  26-09-2022 00:31  Omzet pin             Fris       1\n",
            "3  26-09-2022 00:31  Omzet pin     Sourcy blauw       1\n",
            "4  26-09-2022 00:25  Omzet pin     Sourcy blauw       1\n",
            "\n",
            "Event & Weather Data Sample:\n",
            "   Unnamed: 0            Datum_uur    Omzet       Datum     Tmax     Tmin  \\\n",
            "0          28  2022-07-09 14:00:00     9.00  2022-07-09  21.6 °C  15.3 °C   \n",
            "1          29  2022-07-09 16:00:00   182.35  2022-07-09  21.6 °C  15.3 °C   \n",
            "2          30  2022-07-09 17:00:00   767.10  2022-07-09  21.6 °C  15.3 °C   \n",
            "3          31  2022-07-09 18:00:00  1933.70  2022-07-09  21.6 °C  15.3 °C   \n",
            "4          32  2022-07-09 19:00:00  2567.40  2022-07-09  21.6 °C  15.3 °C   \n",
            "\n",
            "  Neerslag Max Windstoot first_event_date_start  aantal_tickets  \\\n",
            "0   0,0 mm     30.6 km/u    2022-07-09 16:00:00          1319.0   \n",
            "1   0,0 mm     30.6 km/u    2022-07-09 16:00:00          1319.0   \n",
            "2   0,0 mm     30.6 km/u    2022-07-09 16:00:00          1319.0   \n",
            "3   0,0 mm     30.6 km/u    2022-07-09 16:00:00          1319.0   \n",
            "4   0,0 mm     30.6 km/u    2022-07-09 16:00:00          1319.0   \n",
            "\n",
            "   aantal_opgedaagd  \n",
            "0             962.0  \n",
            "1             962.0  \n",
            "2             962.0  \n",
            "3             962.0  \n",
            "4             962.0  \n",
            "final_df shape: (200, 41)\n",
            "Columns after feature engineering: ['Buitenlands mix', 'Desperados', 'Fris', 'Heineken', 'Heineken 0.0', 'RedBull', 'Rosé', 'Sauvignon', 'Shot', 'Shot tequila', 'Sourcy blauw', 'Wijn', 'buitenlands luxe mix', 'event_start', 'event_end', 'Tmax', 'Tmin', 'Neerslag', 'Max Windstoot', 'aantal_tickets', 'aantal_opgedaagd', 'Omzet', 'Chardonney', 'Fles frisdrank', 'Reep', 'Seltzer', 'Fruit', 'cocktail capri', 'Too Late Die Rakete', 'Heineken Bottle', 'Sterk Mix', 'Amaretto Sour', 'Dark & Stormy', 'Mojito', 'Moscow Mule', 'Pornstar Martini', 'Strawberry Daiquiri', 'Virgin Cocktail', 'ANNA Daiquiri', 'Jäger-Mule', 'event_type_day', 'event_type_night', 'season_autumn', 'season_spring', 'season_summer', 'season_winter', 'day_of_week_Friday', 'day_of_week_Monday', 'day_of_week_Saturday', 'day_of_week_Sunday', 'day_of_week_Thursday', 'day_of_week_Wednesday']\n",
            "\n",
            "Total sales per product:\n",
            " Buitenlands mix          8610.0\n",
            "Desperados              50254.0\n",
            "Fris                   167689.0\n",
            "Heineken               360195.0\n",
            "Heineken 0.0             3197.0\n",
            "RedBull                 30405.0\n",
            "Rosé                     3381.0\n",
            "Sauvignon                4085.0\n",
            "Shot                    35491.0\n",
            "Shot tequila             1495.0\n",
            "Sterk Mix               91094.0\n",
            "Amaretto Sour            1058.0\n",
            "Dark & Stormy             653.0\n",
            "Mojito                   1868.0\n",
            "Moscow Mule              2962.0\n",
            "Pornstar Martini         2017.0\n",
            "Strawberry Daiquiri       987.0\n",
            "Virgin Cocktail           216.0\n",
            "ANNA Daiquiri              20.0\n",
            "Jäger-Mule                  7.0\n",
            "dtype: float64\n",
            "\n",
            "High Volume Drinks: ['Desperados', 'Fris', 'Heineken', 'RedBull', 'Shot', 'Sterk Mix']\n",
            "Mid/Low Volume Drinks: ['Buitenlands mix', 'Heineken 0.0', 'Rosé', 'Sauvignon', 'Shot tequila', 'Amaretto Sour', 'Dark & Stormy', 'Mojito', 'Moscow Mule', 'Pornstar Martini', 'Strawberry Daiquiri', 'Virgin Cocktail']\n",
            "Dropping Very Low Volume Drinks: ['ANNA Daiquiri', 'Jäger-Mule']\n",
            "\n",
            "High Volume Model will predict: ['Desperados', 'Fris', 'Heineken', 'RedBull', 'Shot', 'Sterk Mix']\n",
            "Mid/Low Volume Model will predict: ['Buitenlands mix', 'Heineken 0.0', 'Rosé', 'Sauvignon', 'Shot tequila', 'Amaretto Sour', 'Dark & Stormy', 'Mojito', 'Moscow Mule', 'Pornstar Martini', 'Strawberry Daiquiri', 'Virgin Cocktail']\n",
            "Removing 94 outlier rows based on IQR method.\n",
            "New shape after outlier removal: (106, 50)\n",
            "\n",
            "===== HIGH VOLUME MODEL =====\n",
            "\n",
            "===== MID/LOW VOLUME MODEL =====\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# 1. SETUP AND READ DATA\n",
        "#############################################\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Paths to your CSV files\n",
        "sales_path = '/content/filtered_drinks_data.csv'\n",
        "weather_path = '/content/merged_omzet_weer_ticket.csv'\n",
        "\n",
        "# Read data\n",
        "sales_df = pd.read_csv(sales_path)\n",
        "event_weather_df = pd.read_csv(weather_path)\n",
        "\n",
        "print(\"Sales Data Sample:\")\n",
        "print(sales_df.head())\n",
        "print(\"\\nEvent & Weather Data Sample:\")\n",
        "print(event_weather_df.head())\n",
        "\n",
        "#############################################\n",
        "# 2. PREPROCESS & BUILD FINAL_DF\n",
        "#############################################\n",
        "\n",
        "# (A) Parse datetime columns\n",
        "sales_df['Datum'] = pd.to_datetime(sales_df['Datum'], dayfirst=True)\n",
        "event_weather_df['first_event_date_start'] = pd.to_datetime(event_weather_df['first_event_date_start'])\n",
        "\n",
        "# Create event_end = start + 8 hours\n",
        "event_weather_df['event_end'] = event_weather_df['first_event_date_start'] + pd.Timedelta(hours=8)\n",
        "\n",
        "# Classify event as \"day\" or \"night\" based on start time\n",
        "def classify_event_type(dt):\n",
        "    hour = dt.hour\n",
        "    if 14 <= hour < 18:\n",
        "        return \"day\"\n",
        "    else:\n",
        "        return \"night\"\n",
        "\n",
        "event_weather_df['event_type'] = event_weather_df['first_event_date_start'].apply(classify_event_type)\n",
        "\n",
        "\n",
        "# Before applying agg_funcs, convert ALL relevant columns to numeric:\n",
        "event_weather_df['Tmax'] = pd.to_numeric(event_weather_df['Tmax'].str.replace(' °C', ''), errors='coerce')\n",
        "event_weather_df['Tmin'] = pd.to_numeric(event_weather_df['Tmin'].str.replace(' °C', ''), errors='coerce')\n",
        "event_weather_df['Neerslag'] = pd.to_numeric(event_weather_df['Neerslag'].str.replace(',', '.').str.replace(' mm', ''), errors='coerce') # This line is crucial\n",
        "event_weather_df['Max Windstoot'] = pd.to_numeric(event_weather_df['Max Windstoot'].str.extract('(\\d+\\.?\\d*)', expand=False), errors='coerce')\n",
        "\n",
        "\n",
        "# (B) Deduplicate by grouping event_weather_df so each event_start is unique\n",
        "agg_funcs = {\n",
        "    'Tmax': 'mean',\n",
        "    'Tmin': 'mean',\n",
        "    'Neerslag': 'sum',\n",
        "    'Max Windstoot': 'max',\n",
        "    'Omzet': 'sum',\n",
        "    'aantal_tickets': 'max',\n",
        "    'aantal_opgedaagd': 'max'\n",
        "}\n",
        "\n",
        "\n",
        "# Now proceed with the groupby and agg:\n",
        "event_weather_dedup = (\n",
        "    event_weather_df\n",
        "    .groupby('first_event_date_start', as_index=False)\n",
        "    .agg(agg_funcs)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "event_weather_dedup = (\n",
        "    event_weather_df\n",
        "    .groupby('first_event_date_start', as_index=False)\n",
        "    .agg(agg_funcs)\n",
        ")\n",
        "\n",
        "# Re-apply event_end (8h from start)\n",
        "event_weather_dedup['event_end'] = event_weather_dedup['first_event_date_start'] + pd.Timedelta(hours=8)\n",
        "\n",
        "# If multiple rows had different event_type, pick the first (or majority)\n",
        "def pick_event_type(series):\n",
        "    return series.iloc[0]\n",
        "\n",
        "event_type_map = (\n",
        "    event_weather_df\n",
        "    .groupby('first_event_date_start')['event_type']\n",
        "    .apply(pick_event_type)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "event_weather_dedup = pd.merge(\n",
        "    event_weather_dedup,\n",
        "    event_type_map,\n",
        "    on='first_event_date_start',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# (C) Build final_df by merging sales within each 8-hour window\n",
        "final_rows = []\n",
        "for _, event_row in event_weather_dedup.iterrows():\n",
        "    start_time = event_row['first_event_date_start']\n",
        "    end_time   = event_row['event_end']\n",
        "\n",
        "    # Sales within [start_time, end_time)\n",
        "    mask = (sales_df['Datum'] >= start_time) & (sales_df['Datum'] < end_time)\n",
        "    sales_in_window = sales_df.loc[mask]\n",
        "\n",
        "    grouped = sales_in_window.groupby('Product', as_index=False)['Aantal'].sum()\n",
        "    if not grouped.empty:\n",
        "        pivoted = grouped.set_index('Product')['Aantal'].to_frame().T\n",
        "        pivoted_data = pivoted.iloc[0].to_dict()\n",
        "    else:\n",
        "        pivoted_data = {}\n",
        "\n",
        "    # Add event/weather fields\n",
        "    pivoted_data['event_start'] = start_time\n",
        "    pivoted_data['event_end']   = end_time\n",
        "    pivoted_data['event_type']  = event_row['event_type']\n",
        "    pivoted_data['Tmax']        = event_row['Tmax']\n",
        "    pivoted_data['Tmin']        = event_row['Tmin']\n",
        "    pivoted_data['Neerslag']    = event_row['Neerslag']\n",
        "    pivoted_data['Max Windstoot'] = event_row['Max Windstoot']\n",
        "    pivoted_data['aantal_tickets']   = event_row['aantal_tickets']\n",
        "    pivoted_data['aantal_opgedaagd'] = event_row['aantal_opgedaagd']\n",
        "    pivoted_data['Omzet']           = event_row['Omzet']\n",
        "\n",
        "    final_rows.append(pivoted_data)\n",
        "\n",
        "final_df = pd.DataFrame(final_rows)\n",
        "print(\"final_df shape:\", final_df.shape)\n",
        "\n",
        "#############################################\n",
        "# 3. CLEAN AND FEATURE ENGINEERING\n",
        "#############################################\n",
        "\n",
        "# Remove trailing spaces in columns\n",
        "final_df.columns = [col.strip() for col in final_df.columns]\n",
        "\n",
        "# Identify your main drink columns\n",
        "drink_columns = [\n",
        "    'Buitenlands mix','Desperados','Fris','Heineken',\n",
        "    'Heineken 0.0','RedBull','Rosé','Sauvignon','Shot',\n",
        "    'Shot tequila','Sterk Mix','Amaretto Sour','Dark & Stormy',\n",
        "    'Mojito','Moscow Mule','Pornstar Martini','Strawberry Daiquiri',\n",
        "    'Virgin Cocktail','ANNA Daiquiri','Jäger-Mule'\n",
        "]\n",
        "\n",
        "# Fill missing sales with 0\n",
        "final_df[drink_columns] = final_df[drink_columns].fillna(0)\n",
        "\n",
        "# 3.2 (A) Add Season Feature\n",
        "def get_season(date):\n",
        "    m = date.month\n",
        "    if m in [12, 1, 2]:\n",
        "        return \"winter\"\n",
        "    elif m in [3, 4, 5]:\n",
        "        return \"spring\"\n",
        "    elif m in [6, 7, 8]:\n",
        "        return \"summer\"\n",
        "    else:\n",
        "        return \"autumn\"\n",
        "\n",
        "final_df['season'] = final_df['event_start'].apply(get_season)\n",
        "\n",
        "# 3.2 (B) Add Day-of-Week Feature\n",
        "final_df['day_of_week'] = final_df['event_start'].dt.day_name()\n",
        "\n",
        "# One-hot encode event_type, season, day_of_week\n",
        "final_df = pd.get_dummies(final_df, columns=['event_type','season','day_of_week'])\n",
        "\n",
        "# Check the columns now\n",
        "print(\"Columns after feature engineering:\", final_df.columns.tolist())\n",
        "\n",
        "#############################################\n",
        "# 4. SPLIT DRINKS INTO HIGH-VOLUME VS MID/LOW-VOLUME\n",
        "#############################################\n",
        "\n",
        "# Sum total sales for each product\n",
        "product_sums = final_df[drink_columns].sum()\n",
        "print(\"\\nTotal sales per product:\\n\", product_sums)\n",
        "\n",
        "# Decide thresholds\n",
        "HIGH_THRESHOLD = 10_000\n",
        "LOW_THRESHOLD  = 200  # for demonstration, might drop <200 entirely\n",
        "\n",
        "high_volume_drinks = product_sums[product_sums >= HIGH_THRESHOLD].index.tolist()\n",
        "mid_low_drinks = product_sums[(product_sums >= LOW_THRESHOLD) & (product_sums < HIGH_THRESHOLD)].index.tolist()\n",
        "very_low_drinks = product_sums[product_sums < LOW_THRESHOLD].index.tolist()\n",
        "\n",
        "print(\"\\nHigh Volume Drinks:\", high_volume_drinks)\n",
        "print(\"Mid/Low Volume Drinks:\", mid_low_drinks)\n",
        "print(\"Dropping Very Low Volume Drinks:\", very_low_drinks)\n",
        "\n",
        "# Drop extremely low columns\n",
        "final_df.drop(columns=very_low_drinks, inplace=True, errors='ignore')\n",
        "\n",
        "# Re-check your final drink lists\n",
        "drink_columns_high = high_volume_drinks\n",
        "drink_columns_mid_low = mid_low_drinks\n",
        "\n",
        "print(\"\\nHigh Volume Model will predict:\", drink_columns_high)\n",
        "print(\"Mid/Low Volume Model will predict:\", drink_columns_mid_low)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def remove_outliers_iqr(df, columns, multiplier=3):\n",
        "    \"\"\"\n",
        "    Removes rows in df where any of the specified columns\n",
        "    have values outside [Q1 - multiplier*IQR, Q3 + multiplier*IQR].\n",
        "\n",
        "    Returns a cleaned DataFrame.\n",
        "    \"\"\"\n",
        "    outlier_indices = set()\n",
        "\n",
        "    for col in columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - multiplier * IQR\n",
        "        upper_bound = Q3 + multiplier * IQR\n",
        "\n",
        "        # Get indices where the column value is outside the bounds\n",
        "        col_outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
        "        outlier_indices.update(col_outliers)\n",
        "\n",
        "    print(f\"Removing {len(outlier_indices)} outlier rows based on IQR method.\")\n",
        "    df_cleaned = df.drop(index=outlier_indices).reset_index(drop=True)\n",
        "    return df_cleaned\n",
        "\n",
        "# Identify your drink columns\n",
        "drink_columns = [\n",
        "    'Buitenlands mix','Desperados','Fris','Heineken',\n",
        "    'Heineken 0.0','RedBull','Rosé','Sauvignon','Shot',\n",
        "    'Shot tequila','Sterk Mix','Amaretto Sour','Dark & Stormy',\n",
        "    'Mojito','Moscow Mule','Pornstar Martini','Strawberry Daiquiri',\n",
        "    'Virgin Cocktail'\n",
        "]\n",
        "\n",
        "# 1. Outlier Removal\n",
        "final_df = remove_outliers_iqr(final_df, drink_columns, multiplier=3)\n",
        "print(\"New shape after outlier removal:\", final_df.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################\n",
        "# 5. TRAIN TWO SEPARATE MODELS\n",
        "#############################################\n",
        "\n",
        "# Common feature columns (adjust as needed)\n",
        "# Must exist in final_df.columns\n",
        "feature_columns = [\n",
        "    'Tmax','Tmin','Neerslag','Max Windstoot',\n",
        "    'aantal_tickets','aantal_opgedaagd','Omzet',\n",
        "    # One-hot columns for event_type (e.g. event_type_day, event_type_night)\n",
        "    # plus the season_ and day_of_week_ columns\n",
        "]\n",
        "# Let's auto-collect the dummies for event_type_, season_, day_of_week_\n",
        "one_hot_cols = [col for col in final_df.columns if col.startswith('event_type_')\n",
        "                or col.startswith('season_') or col.startswith('day_of_week_')]\n",
        "feature_columns += one_hot_cols\n",
        "\n",
        "# (A) High-Volume Model\n",
        "print(\"\\n===== HIGH VOLUME MODEL =====\")\n",
        "model_df_high = final_df.dropna(subset=feature_columns).copy()\n",
        "X_high = model_df_high[feature_columns].values\n",
        "Y_high = model_df_high[drink_columns_high].values\n",
        "\n",
        "###############################################################################\n",
        "# Transform High-Volume drink columns to log scale\n",
        "###############################################################################\n",
        "import numpy as np\n",
        "\n",
        "# Make a copy so we don’t lose original sales values\n",
        "model_df_high_log = model_df_high.copy()\n",
        "\n",
        "# Replace the target columns in model_df_high_log with their log1p (log(x+1)) version\n",
        "for drink_name in drink_columns_high:\n",
        "    model_df_high_log[drink_name] = np.log1p(model_df_high_log[drink_name])\n",
        "\n",
        "# Now define Y in the log-scale\n",
        "Y_high_log = model_df_high_log[drink_columns_high].values\n",
        "\n",
        "# Proceed with train_test_split on X_high and Y_high_log\n",
        "Xh_train, Xh_test, Yh_train_log, Yh_test_log = train_test_split(\n",
        "    X_high,\n",
        "    Y_high_log,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# rf_high = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# multi_high = MultiOutputRegressor(rf_high)\n",
        "# multi_high.fit(Xh_train, Yh_train)\n",
        "# Yh_pred = multi_high.predict(Xh_test)\n",
        "\n",
        "# # Evaluate\n",
        "# mae_per_drink = []\n",
        "# r2_per_drink = []\n",
        "# for i, dcol in enumerate(drink_columns_high):\n",
        "#     mae_i = mean_absolute_error(Yh_test[:, i], Yh_pred[:, i])\n",
        "#     r2_i = r2_score(Yh_test[:, i], Yh_pred[:, i])\n",
        "#     mae_per_drink.append(mae_i)\n",
        "#     r2_per_drink.append(r2_i)\n",
        "#     print(f\"Drink '{dcol}' => MAE: {mae_i:.2f}, R²: {r2_i:.2f}\")\n",
        "\n",
        "# print(f\"\\n[High-Volume] Average MAE: {np.mean(mae_per_drink):.2f}\")\n",
        "# print(f\"[High-Volume] Average R²: {np.mean(r2_per_drink):.2f}\")\n",
        "\n",
        "# (B) Mid/Low Volume Model\n",
        "print(\"\\n===== MID/LOW VOLUME MODEL =====\")\n",
        "model_df_mid_low = final_df.dropna(subset=feature_columns).copy()\n",
        "X_mid_low = model_df_mid_low[feature_columns].values\n",
        "Y_mid_low = model_df_mid_low[drink_columns_mid_low].values\n",
        "\n",
        "###############################################################################\n",
        "# Transform Mid/Low-Volume drink columns to log scale\n",
        "###############################################################################\n",
        "model_df_mid_low_log = model_df_mid_low.copy()\n",
        "\n",
        "for drink_name in drink_columns_mid_low:\n",
        "    model_df_mid_low_log[drink_name] = np.log1p(model_df_mid_low_log[drink_name])\n",
        "\n",
        "Y_mid_low_log = model_df_mid_low_log[drink_columns_mid_low].values\n",
        "\n",
        "Xm_train, Xm_test, Ym_train_log, Ym_test_log = train_test_split(\n",
        "    X_mid_low,\n",
        "    Y_mid_low_log,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# rf_mid_low = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# multi_mid_low = MultiOutputRegressor(rf_mid_low)\n",
        "# multi_mid_low.fit(Xm_train, Ym_train)\n",
        "# Ym_pred = multi_mid_low.predict(Xm_test)\n",
        "\n",
        "# # Evaluate\n",
        "# mae_per_drink = []\n",
        "# r2_per_drink = []\n",
        "# for i, dcol in enumerate(drink_columns_mid_low):\n",
        "#     mae_i = mean_absolute_error(Ym_test[:, i], Ym_pred[:, i])\n",
        "#     r2_i = r2_score(Ym_test[:, i], Ym_pred[:, i])\n",
        "#     mae_per_drink.append(mae_i)\n",
        "#     r2_per_drink.append(r2_i)\n",
        "#     print(f\"Drink '{dcol}' => MAE: {mae_i:.2f}, R²: {r2_i:.2f}\")\n",
        "\n",
        "# print(f\"\\n[Mid/Low Volume] Average MAE: {np.mean(mae_per_drink):.2f}\")\n",
        "# print(f\"[Mid/Low Volume] Average R²: {np.mean(r2_per_drink):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWMNrVB0jw9R",
        "outputId": "e00a4d0c-1af9-4591-9423-45337286a51b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample weights (High): [ 8.08 56.1  26.62 57.3  47.33 50.69 59.69 24.02  1.   44.45]\n",
            "[Weighted CAT-High] Drink 'Desperados' => MAE: 53.98, R²: 0.19\n",
            "[Weighted CAT-High] Drink 'Fris' => MAE: 225.15, R²: 0.74\n",
            "[Weighted CAT-High] Drink 'Heineken' => MAE: 340.45, R²: 0.70\n",
            "[Weighted CAT-High] Drink 'RedBull' => MAE: 89.31, R²: 0.18\n",
            "[Weighted CAT-High] Drink 'Shot' => MAE: 80.12, R²: 0.24\n",
            "[Weighted CAT-High] Drink 'Sterk Mix' => MAE: 362.05, R²: -0.38\n",
            "\n",
            "[Weighted CAT-High] Avg MAE: 191.85\n",
            "[Weighted CAT-High] Avg R²: 0.28\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "###############################################################################\n",
        "# 1. Define Sample Weights for High Volume\n",
        "###############################################################################\n",
        "# The shape of Yh_train_log is [n_samples, n_drinks_high].\n",
        "# Exponentiate back to original scale to see actual volumes:\n",
        "Yh_train_orig = np.expm1(Yh_train_log)  # shape: (num_rows, num_high_drinks)\n",
        "\n",
        "# Example approach: use the SUM of all high-volume drinks in that row as the row weight\n",
        "row_sum_high = Yh_train_orig.sum(axis=1)  # shape: (num_rows,)\n",
        "# Optionally scale or clamp to avoid zero/huge weights:\n",
        "sample_weights_high = np.maximum(1, row_sum_high / 100.0)  # or any scaling you prefer\n",
        "# sample_weights_high = np.sqrt(1, row_sum_high / 100.0)  # or any scaling you prefer\n",
        "\n",
        "\n",
        "print(\"Sample weights (High):\", sample_weights_high[:10])  # quick peek\n",
        "\n",
        "###############################################################################\n",
        "# 2. Fit CatBoost with sample_weight\n",
        "###############################################################################\n",
        "cat_high = CatBoostRegressor(\n",
        "    iterations=160,\n",
        "    learning_rate=0.07,\n",
        "    depth=4,\n",
        "    random_seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "multi_cat_high = MultiOutputRegressor(cat_high)\n",
        "\n",
        "multi_cat_high.fit(\n",
        "    Xh_train,\n",
        "    Yh_train_log,\n",
        "    sample_weight=sample_weights_high\n",
        ")\n",
        "\n",
        "# Predict in log scale\n",
        "Yh_pred_log = multi_cat_high.predict(Xh_test)\n",
        "\n",
        "# Exponentiate back to original scale\n",
        "Yh_pred = np.expm1(Yh_pred_log)\n",
        "Yh_test_orig = np.expm1(Yh_test_log)\n",
        "\n",
        "# Evaluate\n",
        "mae_list, r2_list = [], []\n",
        "for i, drink_name in enumerate(drink_columns_high):\n",
        "    mae_i = mean_absolute_error(Yh_test_orig[:, i], Yh_pred[:, i])\n",
        "    r2_i = r2_score(Yh_test_orig[:, i], Yh_pred[:, i])\n",
        "    mae_list.append(mae_i)\n",
        "    r2_list.append(r2_i)\n",
        "    print(f\"[Weighted CAT-High] Drink '{drink_name}' => MAE: {mae_i:.2f}, R²: {r2_i:.2f}\")\n",
        "\n",
        "print(f\"\\n[Weighted CAT-High] Avg MAE: {np.mean(mae_list):.2f}\")\n",
        "print(f\"[Weighted CAT-High] Avg R²: {np.mean(r2_list):.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Mid/Low Volume\n",
        "###############################################################################\n",
        "# Fit mid/low model on log scale, then exponentiate predictions\n",
        "###############################################################################\n",
        "# cat_mid = CatBoostRegressor(\n",
        "#     iterations=100,\n",
        "#     learning_rate=0.01,\n",
        "#     depth=6,\n",
        "#     random_seed=42,\n",
        "#     verbose=0\n",
        "# )\n",
        "\n",
        "# multi_cat_mid = MultiOutputRegressor(cat_mid)\n",
        "# multi_cat_mid.fit(Xm_train, Ym_train_log)\n",
        "\n",
        "# Ym_pred_log = multi_cat_mid.predict(Xm_test)\n",
        "# Ym_pred = np.expm1(Ym_pred_log)\n",
        "# Ym_test_orig = np.expm1(Ym_test_log)\n",
        "\n",
        "# mae_list, r2_list = [], []\n",
        "# for i, drink_name in enumerate(drink_columns_mid_low):\n",
        "#     # Evaluate predictions vs actual in original space\n",
        "#     mae_i = mean_absolute_error(Ym_test_orig[:, i], Ym_pred[:, i])\n",
        "#     r2_i = r2_score(Ym_test_orig[:, i], Ym_pred[:, i])\n",
        "#     mae_list.append(mae_i)\n",
        "#     r2_list.append(r2_i)\n",
        "#     print(f\"[CAT-Mid] Drink '{drink_name}' => MAE: {mae_i:.2f}, R²: {r2_i:.2f}\")\n",
        "\n",
        "# print(f\"\\n[CAT-Mid] Avg MAE: {np.mean(mae_list):.2f}\")\n",
        "# print(f\"[CAT-Mid] Avg R²: {np.mean(r2_list):.2f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "nSodenqKn2j3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "def plot_predicted_vs_actual_logscale(Y_true_log, Y_hat_log, drink_cols, num_plots=4):\n",
        "    \"\"\"\n",
        "    Plots predicted vs. actual (in *original* scale) for the first 'num_plots' drinks\n",
        "    in the list 'drink_cols', given that Y_true_log and Y_hat_log\n",
        "    are in log scale (log1p).\n",
        "    \"\"\"\n",
        "    n_drinks = len(drink_cols)\n",
        "    n_plots = min(num_plots, n_drinks)\n",
        "\n",
        "    plt.figure(figsize=(5 * n_plots, 4))\n",
        "    for i in range(n_plots):\n",
        "        # Convert from log-scale back to original scale\n",
        "        actual_vals = np.expm1(Y_true_log[:, i])  # exp(Y) - 1\n",
        "        pred_vals   = np.expm1(Y_hat_log[:, i])\n",
        "\n",
        "        plt.subplot(1, n_plots, i + 1)\n",
        "        sns.scatterplot(x=actual_vals, y=pred_vals, alpha=0.5)\n",
        "\n",
        "        max_val = max(actual_vals.max(), pred_vals.max())\n",
        "        plt.plot([0, max_val], [0, max_val], color='red', linestyle='--')\n",
        "        plt.xlabel(\"Actual (original scale)\")\n",
        "        plt.ylabel(\"Predicted (original scale)\")\n",
        "        plt.title(f\"{drink_cols[i]}: Pred vs. Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNtQDvsNbFI3",
        "outputId": "17f06838-ec64-47b3-c03a-a204446d7a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Median sales for Fris: 645.0\n",
            "Median sales for Heineken: 1433.5\n",
            "Median sales for Desperados: 122.5\n",
            "Median sales for RedBull: 113.5\n"
          ]
        }
      ],
      "source": [
        "# List the columns you want\n",
        "cols = ['Fris', 'Heineken', 'Desperados', 'RedBull']\n",
        "\n",
        "# Calculate median for each of these\n",
        "median_values = final_df[cols].median()\n",
        "\n",
        "\n",
        "for drink_name, med_val in median_values.items():\n",
        "    print(f\"Median sales for {drink_name}: {med_val}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPFSSrOfejCx"
      },
      "source": [
        "## AFWIJKINGEN PER EVENT PREDICTION\n",
        "\n",
        "Heinken is ongeveer 24% van de mediaan <br>\n",
        "Fris is ongeveer 35% van de mediaan <br>\n",
        "Desperados is ongeveer 44% van de mediaan <br>\n",
        "RedBull is ongeveer 78% van de mediaan\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
